{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'], dtype='object')\n",
      "Date\n",
      "2024-02-13 00:00:00-05:00    146.070007\n",
      "2024-02-14 00:00:00-05:00    147.369995\n",
      "2024-02-15 00:00:00-05:00    144.460007\n",
      "2024-02-16 00:00:00-05:00    144.210007\n",
      "2024-02-20 00:00:00-05:00    140.940002\n",
      "Name: Open, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "google = yf.Ticker(\"GOOG\")\n",
    "historical_data = google.history(period=\"5d\")\n",
    "\n",
    "# Print the columns of the dataframe \n",
    "print(historical_data.columns)\n",
    "\n",
    "print(historical_data['Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_26(ticker, time_frame):\n",
    "  \"\"\"\n",
    "  Calculates the Alpha#26 factor for a given ticker.\n",
    "\n",
    "  Args:\n",
    "    ticker: The ticker symbol of the stock.\n",
    "\n",
    "  Returns:\n",
    "    The Alpha#26 factor value.\n",
    "  \"\"\"\n",
    "\n",
    "#   Alpha26: (-1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3))\n",
    "\n",
    "  # Download the historical stock data, where time_frame is a window of time, like \"5y\" or \"1y\"\n",
    "  data = yf.download(ticker, period=time_frame)\n",
    "  # Calculate the volume and high price ranks.\n",
    "  volume_rank = data['Volume'].rolling(window=5).apply(lambda x: pd.Series(x).rank(method='first').iloc[-1])\n",
    "  high_rank = data['High'].rolling(window=5).apply(lambda x: pd.Series(x).rank(method='first').iloc[-1])\n",
    "\n",
    "  # Calculate the correlation between volume and high price ranks.\n",
    "  correlation = volume_rank.rolling(window=5).corr(high_rank)\n",
    "\n",
    "  # Calculate the ts_max.\n",
    "  ts_max = correlation.rolling(window=3).max()\n",
    "\n",
    "  # Calculate the Alpha#26 factor.\n",
    "  alpha_26 = -1 * ts_max\n",
    "\n",
    "  return alpha_26.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vwap(data):\n",
    "    # data = yf.download(ticker, period=time_frame, interval=\"1m\")\n",
    "\n",
    "    # Calculate VWAP\n",
    "    data['TP'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "    data['CumVol'] = data['Volume'].cumsum()\n",
    "    data['CumTP'] = (data['TP'] * data['Volume']).cumsum()\n",
    "    data['VWAP'] = data['CumTP'] / data['CumVol']\n",
    "\n",
    "    return(data['VWAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_27(ticker, time_frame):\n",
    "    # Calculate the rank of volume and VWAP\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "    volume_rank = data['Volume'].rank(method='first')\n",
    "    vwap_rank = get_vwap(data).rank(method='first')\n",
    "\n",
    "    # Calculate the correlation between rank(volume) and rank(VWAP) over a window of 6\n",
    "    correlation_rank = volume_rank.rolling(window=6).corr(vwap_rank)\n",
    "\n",
    "    # Calculate the sum of the correlation over a window of 2 and divide by 2.0\n",
    "    sum_corr = correlation_rank.rolling(window=2).sum() / 2.0\n",
    "\n",
    "    # Calculate the rank of sum_corr\n",
    "    rank_sum_corr = sum_corr.rank(method='first')\n",
    "\n",
    "    # Check if 0.5 < rank_sum_corr and assign -1 or 1 accordingly\n",
    "    alpha_27 = rank_sum_corr.apply(lambda x: -1 if x > 0.5 else 1)\n",
    "\n",
    "    return alpha_27.iloc[-1]  # Return the last value of the Alpha#27 factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(value, min_val, max_val):\n",
    "    # Scale the value to be between 0 and 1\n",
    "    return (value - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_28(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, time_frame)\n",
    "\n",
    "    # Calculate ADV20\n",
    "    data['ADV20'] = data['Volume'].rolling(window=20).mean()\n",
    "\n",
    "    # Calculate correlation between ADV20 and Low over 5 periods\n",
    "    corr_adv_low = data['ADV20'].rolling(window=5).corr(data['Low'])\n",
    "\n",
    "    # Calculate average price\n",
    "    avg_price = (data['High'] + data['Low']) / 2\n",
    "\n",
    "    # Calculate Alpha#28 with scaling\n",
    "    alpha_28 = ((corr_adv_low + avg_price) - data['Close']).mean()\n",
    "\n",
    "    # I scale the value here, though I'm not sure which kind of scaling to use.\n",
    "    min_val = alpha_28.min()\n",
    "    max_val = alpha_28.max()\n",
    "    scaled_alpha_28 = alpha_28.apply(lambda x: min_max_scale(x, min_val, max_val))\n",
    "\n",
    "    return scaled_alpha_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_29(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate necessary intermediate values\n",
    "    delta_close = data['Close'].diff(1)\n",
    "    rank_1 = delta_close.rank(axis=0, method='first')\n",
    "    rank_2 = rank_1.rank(axis=0, method='first')\n",
    "    rank_3 = rank_2 * -1\n",
    "    rank_4 = rank_3.rolling(window=5).sum()\n",
    "    rank_5 = rank_4.rank(axis=0, method='first')\n",
    "    rank_6 = rank_5.rank(axis=0, method='first')\n",
    "    ts_min_1 = rank_6.rolling(window=2).min()\n",
    "    sum_1 = ts_min_1.sum(axis=0)\n",
    "    log_1 = np.log(sum_1)\n",
    "    scale_1 = rank_1 * log_1\n",
    "    rank_7 = scale_1.rank(axis=0, method='first')\n",
    "    rank_8 = rank_7.rank(axis=0, method='first')\n",
    "    product_1 = rank_8 * rank_7\n",
    "    min_1 = product_1.rolling(window=5).min()\n",
    "    min_rank = min_1.rank(axis=0, method='first')\n",
    "    ts_rank_1 = (-1 * data['Close'].pct_change()).shift(-6).rolling(window=5).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1])\n",
    "    ts_rank_2 = ts_rank_1.rolling(window=5).mean()\n",
    "\n",
    "    # Calculate Alpha#29\n",
    "    alpha_29 = (min_rank + ts_rank_2).mean()\n",
    "\n",
    "    return alpha_29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((1.0 - rank(((sign((close - delay(close, 1))) + sign((delay(close, 1) - delay(close, 2)))) + sign((delay(close, 2) - delay(close, 3)))))) * sum(volume, 5)) / sum(volume, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_30(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "    # print(data)\n",
    "\n",
    "    close = data['Close']\n",
    "    volume = data['Volume']\n",
    "\n",
    "    # print(volume)\n",
    "\n",
    "    # Calculate signs\n",
    "    sign_1 = np.sign(close - close.shift(-1)).dropna()\n",
    "    sign_2 = np.sign(close.shift(-1) - close.shift(-2)).dropna()\n",
    "    sign_3 = np.sign(close.shift(-2) - close.shift(-3)).dropna()\n",
    "\n",
    "    # print(sign_1)\n",
    "    # print(\"Sirgn 2\")\n",
    "    # print(sign_2)\n",
    "    # print(\"Done\")\n",
    "\n",
    "    # Calculate rank of the signs - WHY DO WE DO THAT\n",
    "    rank_1 = sign_1.rank()\n",
    "    rank_2 = sign_2.rank()\n",
    "    rank_3 = sign_3.rank()\n",
    "\n",
    "    # print(rank_1)\n",
    "\n",
    "    # Calculate the first part of the formula\n",
    "    part_1 = 1.0 - ((rank_1 + rank_2 + rank_3) / 3.0)\n",
    "\n",
    "    print(part_1)\n",
    "\n",
    "    # Calculate the sum of volume over 5 and 20 periods\n",
    "    sum_volume_5 = volume.rolling(window=5).sum()\n",
    "    sum_volume_20 = volume.rolling(window=20).sum()\n",
    "\n",
    "    # Calculate Alpha#30\n",
    "    alpha_30 = ((part_1 * sum_volume_5) / sum_volume_20).dropna()\n",
    "\n",
    "    return alpha_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ((rank(rank(rank(decay_linear((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m rank(rank(delta(close, \u001b[39m10\u001b[39m)))), \u001b[39m10\u001b[39m)))) \u001b[39m+\u001b[39m rank((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m delta(close, \u001b[39m3\u001b[39m)))) \u001b[39m+\u001b[39m sign(scale(correlation(adv20, low, \u001b[39m12\u001b[39m))))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rank' is not defined"
     ]
    }
   ],
   "source": [
    "((rank(rank(rank(decay_linear((-1 * rank(rank(delta(close, 10)))), 10)))) + rank((-1 * delta(close, 3)))) + sign(scale(correlation(adv20, low, 12))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure obout this\n",
    "def decay_linear(x, d):\n",
    "    weights = np.arange(d, 0, -1).astype('float64')\n",
    "    weights /= weights.sum()\n",
    "    return np.convolve(x, weights, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUCK ON THIS ONE, MOVE ON FOR THE TIME BEING\n",
    "# def alpha_31(ticker, time_frame):\n",
    "\n",
    "#     data = yf.download(ticker, period=time_frame)\n",
    "    \n",
    "#     delta_close_10 = data['Close'].diff(10)\n",
    "\n",
    "#     # Calculate Rank of Delta Close\n",
    "#     rank_delta_close_10 = delta_close_10.rank()\n",
    "\n",
    "#     # Calculate Double Rank of Delta Close\n",
    "#     neg_double_rank_delta_close_10 = -1 * rank_delta_close_10.rank()\n",
    "\n",
    "#     decay_linear_double_rank_delta_close_10 = decay_linear(neg_double_rank_delta_close_10, 10)\n",
    "\n",
    "#     rank_decay_linear_double_rank_delta_close_10 = decay_linear_double_rank_delta_close_10.rank()\n",
    "\n",
    "#     part_1 = rank_decay_linear_double_rank_delta_close_10.rank()\n",
    "\n",
    "#     neg_delta_close_3 = (-1 * data['Close'].diff(3))\n",
    "\n",
    "#     rank_neg_delta_close_3 = neg_delta_close_3.rank()\n",
    "\n",
    "#     part_2 = (part_1 + rank_neg_delta_close_3).rank() # first addition - this covers all the ranks at the beginning of the equation now\n",
    "\n",
    "#     # Calculate Correlation between adv20 and low over 12 periods\n",
    "#     correlation_adv20_low_12 = (data['Volume'].rolling(window=20).mean()).rolling(window=12).corr(data['Low'])\n",
    "\n",
    "#     # Calculate Scale of Correlation\n",
    "#     scale_correlation_adv20_low_12 = correlation_adv20_low_12.apply(lambda x: min_max_scale(x, correlation_adv20_low_12.min(), correlation_adv20_low_12.max()))\n",
    "\n",
    "#     sign_scale_correlation_adv20_low_12 = np.sign(scale_correlation_adv20_low_12)\n",
    "\n",
    "#     alpha_31 = part_2 + sign_scale_correlation_adv20_low_12\n",
    "\n",
    "#     return alpha_31\n",
    "\n",
    "\n",
    "# def scale_function(x):\n",
    "#     return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "# def alpha_31(ticker, time_frame):\n",
    "#     data = yf.download(ticker, period=time_frame)\n",
    "    \n",
    "#     # Calculate Rank of Delta Close\n",
    "#     rank_delta_close_10 = data['Close'].diff(10).rank()\n",
    "#     print(\"Rank of Delta:\", rank_delta_close_10)\n",
    "\n",
    "#     # Calculate Double Rank of Delta Close\n",
    "#     neg_double_rank_delta_close_10 = -1 * rank_delta_close_10.rank()\n",
    "\n",
    "#     # Calculate Linear Decay of Double Rank of Delta Close\n",
    "#     decay_linear_double_rank_delta_close_10 = pd.Series(decay_linear(neg_double_rank_delta_close_10, 10))\n",
    "\n",
    "#     # Calculate Triple Rank of Linear Decay of Double Rank of Delta Close\n",
    "#     triple_rank_decay_linear_double_rank_delta_close_10 = decay_linear_double_rank_delta_close_10.rank()\n",
    "\n",
    "#     # Calculate Rank of Triple Rank of Linear Decay of Double Rank of Delta Close\n",
    "#     rank_triple_rank_decay_linear_double_rank_delta_close_10 = triple_rank_decay_linear_double_rank_delta_close_10.rank()\n",
    "\n",
    "#     # Calculate Rank of Delta Close for the last 3 days\n",
    "#     rank_neg_delta_close_3 = (-1 * data['Close'].diff(3)).rank()\n",
    "\n",
    "#     print(rank_neg_delta_close_3)\n",
    "\n",
    "#     # Calculate Rank of Correlation between adv20 and low over 12 periods\n",
    "#     correlation_adv20_low_12 = data['Volume'].rolling(window=20).mean().rolling(window=12).corr(data['Low'])\n",
    "#     rank_correlation_adv20_low_12 = correlation_adv20_low_12.rank()\n",
    "\n",
    "#     # Calculate Scale of Correlation\n",
    "#     scale_correlation_adv20_low_12 = scale(correlation_adv20_low_12).dropna()\n",
    "#     print(scale_correlation_adv20_low_12)\n",
    "\n",
    "#     # Calculate Sign of Scale of Correlation\n",
    "#     sign_scale_correlation_adv20_low_12 = np.sign(scale_correlation_adv20_low_12).dropna()\n",
    "\n",
    "#     print(rank_triple_rank_decay_linear_double_rank_delta_close_10.dtype)\n",
    "#     print(rank_neg_delta_close_3.dtype)\n",
    "#     print(sign_scale_correlation_adv20_low_12.dtype)\n",
    "\n",
    "#     # Calculate Alpha#31\n",
    "#     alpha_31 = (rank_triple_rank_decay_linear_double_rank_delta_close_10 +\n",
    "#                 rank_neg_delta_close_3 +\n",
    "#                 sign_scale_correlation_adv20_low_12)\n",
    "    \n",
    "#     alpha_31 = alpha_31.dropna()\n",
    "\n",
    "#     return alpha_31\n",
    "\n",
    "def alpha_31(ticker, time_frame):\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    print(data.shape[0])\n",
    "    # print(data['Close'])\n",
    "    \n",
    "    # Calculate rank of delta close\n",
    "    delta_close_10 = data['Close'].diff(10).dropna() # these diff functions is where the NaN came from\n",
    "    # print(delta_close_10)\n",
    "    rank_delta_close_10 = delta_close_10.rank()\n",
    "\n",
    "    # print(\"Checking: \", rank_delta_close_10)\n",
    "\n",
    "    # Calculate double rank of delta close\n",
    "    neg_double_rank_delta_close_10 = -1 * rank_delta_close_10.rank()\n",
    "\n",
    "    # print(\"Checking: \", neg_double_rank_delta_close_10)\n",
    "\n",
    "    # Calculate decay linear of double rank delta close\n",
    "    decay_linear_double_rank_delta_close_10 = decay_linear(neg_double_rank_delta_close_10, 10)\n",
    "\n",
    "    # print(\"Checking: \", decay_linear_double_rank_delta_close_10)\n",
    "\n",
    "    # Calculate triple rank of decay linear of double rank delta close\n",
    "    triple_rank_decay_linear_double_rank_delta_close_10 = pd.DataFrame(decay_linear_double_rank_delta_close_10).rank()\n",
    "\n",
    "    # print(\"Checking: \", triple_rank_decay_linear_double_rank_delta_close_10)\n",
    "\n",
    "    # Calculate rank of triple rank of decay linear of double rank delta close\n",
    "    rank_triple_rank_decay_linear_double_rank_delta_close_10 = triple_rank_decay_linear_double_rank_delta_close_10.rank()\n",
    "\n",
    "    # print(\"Checking: \", rank_triple_rank_decay_linear_double_rank_delta_close_10)\n",
    "\n",
    "    # Calculate rank of delta close for the last 3 days\n",
    "    rank_neg_delta_close_3 = (-1 * data['Close'].diff(3)).rank().dropna()\n",
    "\n",
    "    # print(\"Checking delta rank: \", rank_neg_delta_close_3)\n",
    "\n",
    "    # Calculate correlation between adv20 and low over 12 periods\n",
    "    # print(\"Volume: \", data['Volume'])\n",
    "    adv20_starter = (data['Volume'].dropna()).rolling(window=20)\n",
    "    # print(\"Check me out: \", adv20_starter)\n",
    "    adv20 = (data['Volume'].rolling(window=20).mean().dropna())\n",
    "    # print(\"Checking adv20: \", adv20)\n",
    "    correlation_adv20_low_12 = (adv20.rolling(window=12).corr(data['Low']))\n",
    "\n",
    "    correlation_adv20_low_12 = correlation_adv20_low_12.dropna()\n",
    "\n",
    "    # print(\"Checking: \", correlation_adv20_low_12)\n",
    "\n",
    "    # print(\"Checking: \", correlation_adv20_low_12)\n",
    "\n",
    "    # Calculate scale of correlation\n",
    "    scale_correlation_adv20_low_12 = correlation_adv20_low_12.apply(lambda x: min_max_scale(x, correlation_adv20_low_12.min(), correlation_adv20_low_12.max()))\n",
    "\n",
    "    # print(\"Checking now: \", scale_correlation_adv20_low_12)    \n",
    "\n",
    "    # Calculate sign of scale of correlation\n",
    "    sign_scale_correlation_adv20_low_12 = np.sign(scale_correlation_adv20_low_12)\n",
    "\n",
    "    # print(\"Checking now: \", sign_scale_correlation_adv20_low_12)\n",
    "\n",
    "    # if isinstance(rank_triple_rank_decay_linear_double_rank_delta_close_10, pd.Timestamp):\n",
    "    #     print(\"Variable contains a timestamp\")\n",
    "    # else:\n",
    "    #     print(\"Variable does not contain a timestamp\")\n",
    "\n",
    "    # if isinstance(rank_neg_delta_close_3, pd.Timestamp):\n",
    "    #     print(\"Variable contains a timestamp\")\n",
    "    # else:\n",
    "    #     print(\"Variable does not contain a timestamp\")\n",
    "\n",
    "    # if isinstance(sign_scale_correlation_adv20_low_12, pd.Timestamp):\n",
    "    #     print(\"Variable contains a timestamp\")\n",
    "    # else:\n",
    "    #     print(\"Variable does not contain a timestamp\")\n",
    "\n",
    "    alpha_31 = rank_triple_rank_decay_linear_double_rank_delta_close_10 + rank_neg_delta_close_3 + sign_scale_correlation_adv20_low_12\n",
    "\n",
    "    print(\"Checking now: \", rank_triple_rank_decay_linear_double_rank_delta_close_10)\n",
    "    print(\"Checking now: \", rank_neg_delta_close_3)\n",
    "\n",
    "    print(\"Checking now: \", sign_scale_correlation_adv20_low_12)\n",
    "\n",
    "    return alpha_31\n",
    "\n",
    "def scale(x, a=1):\n",
    "    total_abs = np.sum(np.abs(x))\n",
    "    if total_abs == 0:\n",
    "        return x\n",
    "    return x * (a / total_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_32(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    close = data['Close']\n",
    "    vwap = get_vwap(data)\n",
    "\n",
    "    # Calculate the first part of the formula\n",
    "    part_1 = (close.rolling(window=7).sum() / 7 - close).mean()\n",
    "\n",
    "    # Drop NaN values from vwap and delayed close\n",
    "    vwap_dropna = vwap#.dropna()\n",
    "    close_delayed_dropna = close.shift(-5)#.dropna()\n",
    "\n",
    "    close_delayed_dropna = close_delayed_dropna#.dropna()\n",
    "\n",
    "    # Calculate the second part of the formula\n",
    "    # part_2 = 20 * np.corrcoef(vwap_dropna, close_delayed_dropna)[0, 1]\n",
    "\n",
    "    # print(\"Correlation Check: \", vwap_dropna.corr(close_delayed_dropna))\n",
    "\n",
    "    part_2 = 20 * vwap_dropna.corr(close_delayed_dropna)\n",
    "\n",
    "    # print(part_2)\n",
    "\n",
    "    # Scale the two parts and sum them\n",
    "    alpha_32 = part_1 + part_2\n",
    "    alpha_32 = min_max_scale(alpha_32.min(), alpha_32.max(), 230) # Does this make any sense?\n",
    "\n",
    "    return alpha_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_33(ticker, time_frame):\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "    open_price = data['Open']\n",
    "    close_price = data['Close']\n",
    "    alpha = -1 * ((1 - (open_price / close_price)) ** 1)\n",
    "    return alpha.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_34(ticker, time_frame):\n",
    "\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "    returns = data['Close'].pct_change()\n",
    "    std_dev_2 = returns.rolling(window=2).std()\n",
    "    std_dev_5 = returns.rolling(window=5).std()\n",
    "\n",
    "    part_1 = 1 - std_dev_2.rank(pct=True) / std_dev_5.rank(pct=True)\n",
    "    part_2 = 1 - returns.diff(1).rank(pct=True)\n",
    "\n",
    "    alpha = (part_1 + part_2).rank()\n",
    "    return alpha.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_35(ticker, time_frame):\n",
    "\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    volume = data['Volume']\n",
    "    close = data['Close']\n",
    "    high = data['High']\n",
    "    low = data['Low']\n",
    "    returns = data['Close'].pct_change()\n",
    "\n",
    "    ts_rank_volume = volume.rolling(window=32).apply(lambda x: (x.rank()[-1] - 1) / (len(x) - 1)).values[-1]\n",
    "    ts_rank_price = ((close + high - low).rolling(window=16).apply(lambda x: (x.rank()[-1] - 1) / (len(x) - 1))).values[-1]\n",
    "    ts_rank_returns = returns.rolling(window=32).apply(lambda x: (x.rank()[-1] - 1) / (len(x) - 1)).values[-1]\n",
    "\n",
    "    alpha = ts_rank_volume * (1 - ts_rank_price) * (1 - ts_rank_returns)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_36(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    close = data['Close']\n",
    "    open_ = data['Open']\n",
    "    volume = data['Volume']\n",
    "    returns = data['Close'].pct_change()\n",
    "    adv20 = data['Volume'].rolling(window=20).mean()\n",
    "    vwap = (data['Close'] * data['Volume']).cumsum() / data['Volume'].cumsum()\n",
    "\n",
    "    rank_correlation = (2.21 * (close - open_).rolling(window=15).corr(volume.shift(-1))).rank(pct=True)\n",
    "    rank_open_close = (0.7 * (open_ - close).rank(pct=True))\n",
    "    rank_ts_rank_returns = (0.73 * returns.shift(-6).rolling(window=5).apply(lambda x: (x.rank()[-1] - 1) / (len(x) - 1))).rank(pct=True)\n",
    "    rank_abs_correlation = abs(vwap.rolling(window=6).corr(adv20)).rank(pct=True)\n",
    "    rank_sum_close = (0.6 * ((close.rolling(window=200).sum() / 200 - open_) * (close - open_))).rank(pct=True)\n",
    "\n",
    "    alpha = rank_correlation + rank_open_close + rank_ts_rank_returns + rank_abs_correlation + rank_sum_close\n",
    "    return alpha.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_37(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    open_ = data['Open']\n",
    "    close = data['Close']\n",
    "\n",
    "    # Calculate Alpha#37\n",
    "    rank_correlation = (open_.shift(1) - close).rolling(window=200).corr(close).rank(pct=True)\n",
    "    rank_open_close = (open_ - close).rank(pct=True)\n",
    "\n",
    "    alpha = rank_correlation + rank_open_close\n",
    "    return alpha.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_38(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    close = data['Close']\n",
    "    open_ = data['Open']\n",
    "\n",
    "    # Calculate Alpha#38\n",
    "    ts_rank_close = close.rolling(window=10).apply(lambda x: np.argsort(x).argsort()[0], raw=True)\n",
    "    rank_ts_rank_close = ts_rank_close.rank(pct=True)\n",
    "    rank_close_open = (close / open_).rank(pct=True)\n",
    "\n",
    "    alpha = -1 * rank_ts_rank_close * rank_close_open\n",
    "    return alpha.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_39(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    close = data['Close']\n",
    "    volume = data['Volume']\n",
    "\n",
    "    # Calculate Alpha#39\n",
    "    delta_close_7 = close.diff(7)\n",
    "    adv20 = volume.rolling(window=20).mean()\n",
    "    decay_linear_volume_adv20 = volume / adv20\n",
    "    rank_decay_linear_volume_adv20 = decay_linear_volume_adv20.rolling(window=9).apply(lambda x: np.argsort(x).argsort()[0], raw=True).rank(pct=True)\n",
    "    rank_delta_close_7 = delta_close_7.rank(pct=True)\n",
    "    sum_returns_250 = (data['Close'].pct_change()).rolling(window=250).sum().rank(pct=True)\n",
    "\n",
    "    alpha = (-1 * rank_delta_close_7 * (1 - rank_decay_linear_volume_adv20)) * (1 + sum_returns_250)\n",
    "    return alpha.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_40(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate the standard deviation of high prices over a 10-day window\n",
    "    stddev_high_10 = data['High'].rolling(window=10).std()\n",
    "\n",
    "    # Calculate the correlation between high prices and volume over a 10-day window\n",
    "    correlation_high_volume_10 = data['High'].rolling(window=10).corr(data['Volume'])\n",
    "\n",
    "    # Calculate Alpha#40\n",
    "    alpha_40 = (-1 * stddev_high_10.rank()) * correlation_high_volume_10\n",
    "\n",
    "    return alpha_40.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_41(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate Alpha#41\n",
    "    alpha_41 = (data['High'] * data['Low']) ** 0.5 - get_vwap(data)\n",
    "\n",
    "    return alpha_41.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_42(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate VWAP\n",
    "    vwap = get_vwap(data)\n",
    "\n",
    "    # Calculate Alpha#42\n",
    "    alpha_42 = ((vwap - data['Close']).rank() / (vwap + data['Close']).rank()).dropna()\n",
    "\n",
    "    return alpha_42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_43(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate ADV20 (average daily volume over the last 20 days)\n",
    "    data['ADV20'] = data['Volume'].rolling(window=20).mean()\n",
    "\n",
    "    # Calculate Alpha#43\n",
    "    alpha_43 = data['Volume'] / data['ADV20']\n",
    "    ts_rank_1 = alpha_43.rolling(window=20).apply(lambda x: (pd.Series(x).rank(pct=True).iloc[-1] * 100))\n",
    "    delta_close = -1 * data['Close'].diff(7)\n",
    "    ts_rank_2 = delta_close.rolling(window=8).apply(lambda x: (pd.Series(x).rank(pct=True).iloc[-1] * 100))\n",
    "    alpha_43 = ts_rank_1 * ts_rank_2\n",
    "\n",
    "    return alpha_43.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_44(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate Alpha#44\n",
    "    alpha_44 = -1 * data['High'].rolling(window=5).corr(data['Volume'].rank())\n",
    "\n",
    "    return alpha_44.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_45(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate Alpha#45\n",
    "    delay_close = data['Close'].shift(-5)\n",
    "    sum_delay_close_20 = delay_close.rolling(window=20).sum()\n",
    "    rank_1 = (sum_delay_close_20 / 20).rank()\n",
    "    correlation_1 = data['Close'].rolling(window=2).corr(data['Volume'])\n",
    "    rank_2 = correlation_1.rank()\n",
    "    sum_close_5 = data['Close'].rolling(window=5).sum()\n",
    "    sum_close_20 = data['Close'].rolling(window=20).sum()\n",
    "    correlation_2 = sum_close_5.rolling(window=2).corr(sum_close_20)\n",
    "    rank_3 = correlation_2.rank()\n",
    "    alpha_45 = -1 * ((rank_1 * correlation_1) * rank_2 * rank_3)\n",
    "\n",
    "\n",
    "    return alpha_45.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_46(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate Alpha#46\n",
    "    condition = ((data['Close'].shift(20) - data['Close'].shift(-10)) / 10) - ((data['Close'].shift(10) - data['Close']) / 10)\n",
    "    alpha_46 = np.where((0.25 < condition), -1, np.where((condition < 0), 1, -1 * (data['Close'] - data['Close'].shift(1))))\n",
    "\n",
    "    return pd.Series(alpha_46, index=data.index).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_47(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate ADV20 (average daily volume over the last 20 days)\n",
    "    data['ADV20'] = data['Volume'].rolling(window=20).mean()\n",
    "\n",
    "    # Calculate Alpha#47\n",
    "    rank_close = 1 / data['Close'].rank()\n",
    "    alpha_47 = ((rank_close * data['Volume']) / data['ADV20']) * ((data['High'] * data['High'].rank()) / (data['High'].rolling(window=5).mean() / 5)) - (get_vwap(data) - get_vwap(data).shift(5)).rank()\n",
    "\n",
    "    return alpha_47.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_48(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate Alpha#48\n",
    "    delta_close_1 = data['Close'].diff(1)\n",
    "    correlation_1 = delta_close_1.rolling(window=250).corr(data['Close'].shift(-1).diff(1))\n",
    "    sum_1 = (delta_close_1 / data['Close'].shift(-1)) ** 2\n",
    "    alpha_48 = indneutralize((correlation_1 * delta_close_1 / data['Close']) / sum_1.rolling(window=250).sum(), IndClass.subindustry) # I don't know what to do for indneutralize\n",
    "\n",
    "    return alpha_48.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_49(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate Alpha#49\n",
    "    condition = ((data['Close'].shift(-20) - data['Close'].shift(-10)) / 10) - ((data['Close'].shift(-10) - data['Close']) / 10) < (-1 * 0.1)\n",
    "    alpha_49 = np.where(condition, 1, -1 * (data['Close'] - data['Close'].shift(-1)))\n",
    "\n",
    "    return pd.Series(alpha_49, index=data.index).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_50(ticker, time_frame):\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, period=time_frame)\n",
    "\n",
    "    # Calculate Alpha#50\n",
    "    rank_volume = data['Volume'].rank()\n",
    "    rank_vwap = get_vwap(data).rank()\n",
    "    correlation_rank = rank_volume.rolling(window=5).corr(rank_vwap)\n",
    "    alpha_50 = -1 * correlation_rank.rank(method='first').rolling(window=5).max()\n",
    "\n",
    "    return alpha_50.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing alpha:  -0.0\n",
      "Printing alpha:  -1\n",
      "Printing alpha:  628.347373493976\n",
      "Date\n",
      "2019-02-26           NaN\n",
      "2019-02-27           NaN\n",
      "2019-02-28   -915.000000\n",
      "2019-03-01   -915.000000\n",
      "2019-03-04   -915.000000\n",
      "                 ...    \n",
      "2024-02-16   -495.833333\n",
      "2024-02-20   -496.166667\n",
      "2024-02-21   -705.666667\n",
      "2024-02-22   -915.000000\n",
      "2024-02-23   -915.000000\n",
      "Name: Close, Length: 1258, dtype: float64\n",
      "Printing alpha:  Date\n",
      "2019-03-22   -187.279897\n",
      "2019-03-25   -134.655325\n",
      "2019-03-26    -80.284351\n",
      "2019-03-27    -71.498522\n",
      "2019-03-28    -70.579169\n",
      "                 ...    \n",
      "2024-02-16   -106.550252\n",
      "2024-02-20   -108.839358\n",
      "2024-02-21   -151.530308\n",
      "2024-02-22   -207.252275\n",
      "2024-02-23   -177.499382\n",
      "Length: 1240, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing alpha: \", alpha_26(\"GOOG\", \"5y\"))\n",
    "print(\"Printing alpha: \", alpha_27(\"GOOG\", \"5y\"))\n",
    "# print(\"Printing alpha: \", alpha_28(\"GOOG\", \"5y\"))\n",
    "print(\"Printing alpha: \", alpha_29(\"GOOG\", \"5y\"))\n",
    "print(\"Printing alpha: \", alpha_30(\"GOOG\", \"5y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing alpha:  125.54767932489452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing alpha: \", alpha_29(\"AAPL\", \"1y\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "get_measurements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3b3837ea1354e54c7103e3a8bb35853e57d1295af65b86ad719f2962c722192"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
